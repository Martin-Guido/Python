# -*- coding: utf-8 -*-
"""4-16-48-1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10VzNQt7UHASNV5lQm4GAY5d30SzwPKzS
"""

#llamamos las librerias con las funciones de Python.
import numpy as np
import math as mt
import scipy as sc
import matplotlib.pyplot as plt
from sklearn.datasets import make_circles



#Para poder trabajar con los datos, declaramos las siguientes variables. Las cuales luego van a almacenar los datos del archivo.
datos1=[]
datos2=[]
datos3=[]
datos4=[]
datos5=[]
mes=[]
tmed=[]
viento=[]
presion=[]
lluvia=[]
x=[]
y=[]
#####################################################################################################################################
#Aca abrimos el archivo de nombre 2013.text con los datos del mes la temperatura el viento, la presion y la lluvia.
file=open('2013.text','r')
#definimos contenido tal que pueda almacenar los datos hasta encontrar un tabulador '\t'
contenido=file.readlines()
for i in range (0,len(contenido),1):  #(usaré como separador el tabulador)
   dato1=contenido[i].find('\t')
   dato2=contenido[i].find('\t',dato1+1)
   dato3=contenido[i].find('\t',dato2+1)
   dato4=contenido[i].find('\t',dato3+1)
   dato5=contenido[i].find('\t',dato4+1)

#  Así sucesivamente hasta que posiciones todos los separadores (en el caso de que tu archivo tenga un número de columnas fijo)
#(se supone que un número por eso uso float)
   valor1=float(contenido[i][0:dato1]) 
   valor2=float(contenido[i][dato1+1:dato2])
   valor3=float(contenido[i][dato2+1:dato3])
   valor4=float(contenido[i][dato3+1:dato4])
   valor5=float(contenido[i][dato4+1:dato5])
   mes.append(valor1)
   tmed.append(valor2)
   viento.append(valor3)
   presion.append(valor4)
   lluvia.append((valor5))
   x.append([mes[i],tmed[i],viento[i],presion[i]])
#almacenamos los datos en listas y luego las convertimos en vectores para trabajar con la biblioteca numpy econ el array.
#siendo los valores de almacenados en <<X>> los datos que usaremos en la capa de entrada y <<Y>> el valor de la lluvia el cual deseamos hallar.
x=np.array(x)   
y=np.array(lluvia)
p=len(x.T)

#Modulador
#
#Hace el tratamiento a los datos para adaptarlos en un rango de 0 a 1 para luego utilizar la funcion de activacion.
def mod(x):
  #Se define la funcion elmo la cual al ser aplicada a cada valor hace una division entre la diferencia del maximo 
  #y el minimo de los vectores que presentan los valores de cada variable.
 elmo=lambda z,a:(z-min(a))/(max(a)-min(a))  
 c=[]
 #se realiza un tratamiento distinto para los valores de <<Y>> que para los de <<X>> ya que las dimenciones del vector <<Y>> son (57,)
 # la cual genera errores en el proceso.

 if len(x.T)==len(x):
  for j in range(len(x)):
      c.append(elmo(x[j],y))
 #este proceso separa los vectores columnas del array de <<X>> para poder hacer un tratamiento a cada tipo de variable por separado. 
 #es decir los vientos con el viento, la presion con la presion...etc
 #la funcion esta preparada para mas tipos de variables.
 else:
  for i in range(len(x.T)):
    a=[]
    b=[]
    
    for j in range(len(x)):
      a.append(x[j][i])

   
    for j in range(len(x)):
      b.append(elmo(x[j][i],a))
    c.append(b)
 return np.array(c).T

##Ordenador
#se aplica un ordenador de datos porque se vio que optimizaba el trabajo de aprendisaje de la red neuronal
#lo que hace es organizar los valores de precipitacion los del array<<Y>> y los ordena de menor a mayor en un nuevo vector b y almacenos los valores de y en c
def ordenador(x,y):
  b=sorted(y)
  c=y
  h=mod(x)
  a=[]
  k=0
#Luego va recoriendo los valores del vector ordenado comparandolo con cada elemento del vector sin ordenar
# para almacenar en a el vector ordenado de las variable guardadas anteriormente en <<X>>
  for i in range(len(h)):
    s=0
    i=i-k
    for j in range(len(b)):
  
      if s==0 and b[i]==c[j]:
        s=1
        k=k+1
        a.append(h[j])
   #se eliminan los elementos ya escritos para no repetir el mismo valor de <<X[j]>> si llega a repetirse el valor de <<Y[j]>> 
        h=np.delete(h, j,axis=0)
       
        b=np.delete(b, i,axis=0)
        c=np.delete(c, j,axis=0)
        #al eliminarse los elementos la variable k vendria a ser una correccion a la posicion 
  return np.array(a)

#Esta funcion devuelve el orden original de los datos iniciales.
#Como variable asume que los datos que reciben esta ordenado de menor a mayor.

def reordenador(x,y):
  
  

  #print(b)
  h=sorted(y)
  c=y
  a=[]
  k=0
  for i in range(len(h)):
    s=0
    i=i-k
    for j in range(len(x)):
     
      if s==0 and c[i]==h[j]:
        s=1
        k=k+1
        a.append(x[j])
       
        h=np.delete(h, j,axis=0)
 
        x=np.delete(x, j,axis=0)
        c=np.delete(c, i,axis=0)
    
  return a

#activacion
sigm=lambda x:0.5*np.tanh(x)+0.5
#sigm=lambda x:(-np.tanh(-5*x)+1+2/(1+np.exp(-x)))/4
  
#df=lambda x: ((2*np.exp(-x))/((1+np.exp(-x))**2) +5*(0.5*(np.exp(-5*x)+np.exp(5*x)))**-2)/4
  
df=lambda z: 0.5*(0.5 * (np.exp(z) + np.exp(-z)))**-2

#CLASES DE NEURONAS
#Genera las variables que controlan los pesos de las sinapsis
#que al principio los genera con un valor aleatorio
class neural_layer():
 def __init__(self, n_conn, n_neur):
  
  self.b = np.random.rand(1, n_neur)*2-1
  self.w = np.random.rand(n_conn, n_neur)*2-1
# Crea una red en base al vector Topology
# Siendo topology como una artitectura de la red siendo lo valores iniciales y 
# finales la capa de entrada y salida mientras que las otras
# son de las capas ocultas
topology=[4,2,1]
def create_nn(topology):
  nn=[]
  for l, layer in enumerate(topology[:-1]):
   nn.append(neural_layer(topology[l], topology[l+1]))
  g=np.array(nn)
  return g
  #print(g)
create_nn(topology)
# Se crea la funcion que calcula el error de la red
l2_cost = (lambda yp,yr:np.linalg.norm((yp-yr)) , lambda yp,yr:(yp-yr))

#  Topology es la Arquitectura de la red neuronal

topology =[p,16,1]
#genero los pesos sinapticos de la red para almacenar los valores
neural_net = create_nn(topology)

# Se definen la funcion train la cual llama las funciones anterior mente 
# definidas, las variables con los datos <<X>> y con los datos de la lluvia <Y>
# siendo << lr >> la velocidad de aprendizaje
def train(neural_net, x,y, l2_cost,ordenador,reordenador,mod, lr=0.8,train=True): 
 # rec es la variable donde se almacena el vector <<Y>> para luego reordenar 
 # la variable del resultado
  rec=mod(y)
 # Se rescriben los valores de <<Y>> para que esten entre 0 y 1.
 # y luego son ordenados de menor a menor
  y=mod(np.array(sorted(y)))
 # Se guardan los valores de <<X>> ordenados con respecto al orden 
 # de menor a mayor de <<Y>> en <<Cin>> 
  Cin=ordenador(x,y)
 # Se crea la variable <<result>> la cual va
 # a almacenar los datos de la red neuronal 
  result=[]
  # Inicia el proceso de entrenamiento 
  for i in range(len(x)):
    #Almacena los datos de las capa de entrada en <<out>> como vectores 
      out=[(None,Cin[i])]
    

     #recore los vectores de la red neuronal
      for l, layer in enumerate(neural_net):
          
              h=np.array(out[-1][1],ndmin=2)
          
              z= np.array(h@neural_net[l].w + neural_net[l].b,ndmin=2)

        


        
              j=[]
              
              j=[sigm(z[0])]
              a=np.array(j,ndmin=2)
                
             
             
           
              
              j.append(j)
            
              out.append((z, a))
         
      result.append(a[0][0])  
             

      if l==len(neural_net)-1:
                
                v=0
                
                for n in range(len(a.T)):
                    f=neural_net[l].w
                    c=neural_net[l].b
                
                    c1= l2_cost[1](a[0][0],y) 
              
                    v=mt.fabs(a[0][n])*(1-(mt.fabs(a[0][n])))*y[i]+v
                 
                
              
                if i==len(x)-1:
                 f=neural_net[l].w
                 c=neural_net[l].b
              


      if train:    
         delta=[]

         for l in reversed(range(0, len(neural_net))):
         
            a=out[l+1][1]   
           
            if l == len(neural_net)-1  :
               
            
               e=l2_cost[1](a[0],y[i])
               delta.insert(0,l2_cost[1](a[0],y[i])*df(a[0]))
               
            else :
             
               delta.insert(0,np.array(delta[0]@ _w.T)*np.array(df(a[0])))
           
            _w=neural_net[l].w
           
            neural_net[l].b = neural_net[l].b -np.mean(delta[0],axis=0,keepdims=True)*lr
          
            neural_net[l].w = neural_net[l].w -(np.matrix(out[l][1])).T @ np.array(delta[0],ndmin=2)*lr
         
 # Re ordena los datos calculados  
  result=reordenador(result,rec) 
  return result

  
  
train(neural_net, x,y, l2_cost,ordenador,reordenador,mod, lr=0.8,train=True)
#print("")

"""# Sección nueva"""

import time
from IPython.display import clear_output
neural_n = create_nn(topology)
po=100
print('x=',x,'y=',y)
loss = []
loss2=[]
i=0
y=mod(y)
file=open('4-16-1.txt','w')
while i<50000:
  # Entrenemos a la red!
  pY =train(neural_net, x,y, l2_cost,ordenador,reordenador,mod, lr=0.00751,train=True)
  i=i+1
  ist=str(i)


    
  
  
  loss.append(l2_cost[0](pY, y)*316)
  po=loss[-1]
  pos=str(loss[-1])
 
  file.write(ist + '\t' + pos+ '\n') 

  clear_output(wait=True)
  plt.show()
  plt.plot(range(len(loss)), loss)
  plt.savefig('name-4-16-1')
  plt.show()
  print('Error=',loss[-1])
  print('dy=',np.array((pY-y)/(y+1))*100)
  print('py',np.array(pY)*316)
    
  
  time.sleep(0.5)

file.close()

datos1=[]
datos2=[]
datos3=[]
datos4=[]
datos5=[]
mes=[]
tmed=[]
viento=[]
presion=[]
lluvia=[]
x=[]
y=[]
file=open('2019','r')
contenido=file.readlines()
for i in range (0,len(contenido),1):  #(usaré como separador el tabulador)
   dato1=contenido[i].find('\t')
   dato2=contenido[i].find('\t',dato1+1)
   dato3=contenido[i].find('\t',dato2+1)
   dato4=contenido[i].find('\t',dato3+1)
   dato5=contenido[i].find('\t',dato4+1)

#  Así sucesivamente hasta que posiciones todos los separadores (en el caso de que tu archivo tenga un número de columnas fijo)

   valor1=float(contenido[i][0:dato1]) #(se supone que un número po eso uso float)
   valor2=float(contenido[i][dato1+1:dato2])
   valor3=float(contenido[i][dato2+1:dato3])
   valor4=float(contenido[i][dato3+1:dato4])
   valor5=float(contenido[i][dato4+1:dato5])
   mes.append(valor1)
   tmed.append(valor2)
   viento.append(valor3)
   presion.append(valor4)
   lluvia.append((valor5))
   x.append([mes[i],tmed[i],viento[i],presion[i]])
x=np.array(x)   
y=np.array(lluvia)
p=(len(x.T))
print('y',y)
#
pY = train(neural_net, x,y, l2_cost,ordenador,reordenador,mod, lr=0.01,train=True)
g=l2_cost[0](pY, mod(y))
print(np.array(g)*max(y),np.array(pY)*max(y),np.array(y))
print('dy=',np.array((pY-mod(y))*max(y)))

datos1=[]
datos2=[]
datos3=[]
datos4=[]
datos5=[]
mes=[]
tmed=[]
viento=[]
presion=[]
lluvia=[]

y [ 29.   46.   37.  102.   37.   41.   36.    0.4]
129.3335292969722 [2.25953753e+01 7.07948703e-04 2.53672657e+01 2.30238294e-03
 4.93956316e-03 1.64583279e-03 2.95999842e+01 3.18179301e+01] [ 29.   46.   37.  102.   37.   41.   36.    0.4]
dy= [  -6.11722314  -45.77881961  -11.37682879 -101.99769762  -36.73915493
  -40.75819669   -6.14017332   31.81793007]



